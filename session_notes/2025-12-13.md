# Session: 2025-12-13

## Worked On
- Set up session notes mechanism (`session_notes/` directory + CLAUDE.md reminder)
- Reviewed generic verifier state
- **Implemented two-step verification architecture**

## Implementation Summary

### New Architecture: Two-Step Verification

```
┌─────────────────┐
│   Raw Input     │
│   Raw Output    │
└────────┬────────┘
         │
         ▼
┌─────────────────┐     ┌─────────────────┐
│  Fact Extractor │ ──→ │ ExtractedInput  │
│                 │     │ ExtractedOutput │
└─────────────────┘     └────────┬────────┘
                                 │
         ┌───────────────────────┴───────────────────────┐
         │                                               │
         ▼                                               ▼
┌─────────────────┐                           ┌─────────────────┐
│ Step 1:         │                           │ Step 2:         │
│ Consistency     │                           │ Common Sense    │
│ Check           │                           │ Check           │
└────────┬────────┘                           └────────┬────────┘
         │                                             │
         │         ┌─────────────────┐                 │
         └────────→│ Combined Result │←────────────────┘
                   └─────────────────┘
```

### New Files Created
- `script/verifier/generic_fact_extractor.py` - Fact extraction + consistency check
  - `ExtractedInputFacts` - task_goal, visible_elements, error_messages, action_history
  - `ExtractedOutputFacts` - stated_observations, reasoning_steps, action_target
  - `check_consistency()` - Step 1 verification

### Modified Files
- `script/verifier/generic_verifier.py` - Added two-step verification
  - `_verify_two_step()` - Main entry point
  - `_check_common_sense()` - Step 2 verification
  - `_get_input_text()` - Extract raw input text
- `script/verifier/__init__.py` - Export new classes
- `script/test_generic_verifier.py` - Added 7 new tests (23 total)

### Verification Logic

**Step 1: Consistency Check** (input vs output)
- Ungrounded references - agent references things not in observations
- Ignored errors - agent ignores error messages
- Ignored history - agent repeats failed actions
- State mismatch - stated observations contradict actual state
- Fabrication - agent claims to see things not present

**Step 2: Common Sense Check** (is behavior rational?)
- Given the goal, does this action make progress?
- Is the agent repeating a failed action?
- Is the agent ignoring obvious blockers?
- Does the action contradict the reasoning?

### Test Results
```
Ran 23 tests in 0.544s - OK
```

## Current State

### Generic Verifier Files
- `script/verifier/generic_verifier.py` - Main verifier (two-step)
- `script/verifier/generic_fact_extractor.py` - Fact extraction
- `script/verifier/generic_schema.py` - Schema definitions
- `script/test_generic_verifier.py` - Unit tests (23 tests)
- `docs/generic-hallucination-detector.md` - Documentation

## Next Steps
1. **Test on real data** - Run two-step verifier on actual inference results
2. **Analyze violation patterns** - Collect common violations across scenarios
3. **Extract rules** - Convert common sense patterns to Datalog rules
4. **Hybrid approach** - Fast Datalog rules + LLM fallback

## Real Data Test Results

Tested on `repetitive_4/gpt-4o-mini-2024-07-18` (3 cases):

| Case | Hallucination | Step 1 Violations | Step 2 Violations |
|------|--------------|-------------------|-------------------|
| webarena.168 | ✅ Yes | 2 | 2 |
| webarena.489 | ✅ Yes | 2 | 2 |
| webarena.6 | ✅ Yes | 3 | 3 |

**Violation types detected:**
- Step 1: `ignored_history`, `ignored_error`, `state_mismatch`, `ungrounded_reference`
- Step 2: `repeated_failure`, `ignored_evidence`, `reasoning_mismatch`, `goal_deviation`

**Key finding:** Both steps catch violations from different angles:
- Step 1: "Your claims don't match reality"
- Step 2: "Your behavior doesn't make sense"

## Hybrid Verifier (Soufflé + LLM)

Implemented hybrid approach: **Soufflé for consistency (FREE) + LLM for common sense**

### New Files
- `script/verifier/generic_consistency.dl` - Datalog rules for consistency
- `script/verifier/souffle_generic_verifier.py` - Hybrid verifier

### Architecture
```
Input/Output → LLM Fact Extraction → Soufflé (FREE) → LLM Common Sense → Result
```

### Test Results (3 cases)
| Case | Soufflé Violations | LLM Violations | Hallucination |
|------|-------------------|----------------|---------------|
| webarena.168 | 4 | 3 | ✅ Yes |
| webarena.489 | 5 | 3 | ✅ Yes |
| webarena.6 | 12 | 3 | ✅ Yes |

### Soufflé Violations (FREE)
- `ungrounded_reference` - Agent references things not visible
- `ignored_error` - Agent ignores error messages
- `target_not_visible` - Agent targets invisible elements

### LLM Violations
- `reasoning_mismatch` - Action contradicts reasoning
- `goal_deviation` - Action doesn't serve goal
- `state_confusion` - Agent misunderstands state

### CLI Usage
```bash
# Pure LLM (both steps)
python3 verifier.py --use-generic-verifier ...

# Hybrid: Soufflé (Step 1) + LLM (Step 2)
python3 verifier.py --use-souffle-generic-verifier ...
```

## Open Questions
- How to reduce fact extraction cost (currently still uses LLM)?
- Can we make fact extraction rule-based too?
- Performance comparison: hybrid vs pure LLM accuracy
